<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Gridwise Scan and Reduce | Gridwise</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Gridwise Scan and Reduce" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Understand scan (parallel prefix) and reduce operations - fundamental parallel compute primitives for high-performance applications." />
<meta property="og:description" content="Understand scan (parallel prefix) and reduce operations - fundamental parallel compute primitives for high-performance applications." />
<link rel="canonical" href="http://localhost:4000/gridwise/docs/2025/09/16/scan-and-reduce/" />
<meta property="og:url" content="http://localhost:4000/gridwise/docs/2025/09/16/scan-and-reduce/" />
<meta property="og:site_name" content="Gridwise" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-09-16T00:00:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Gridwise Scan and Reduce" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-09-16T00:00:00-04:00","datePublished":"2025-09-16T00:00:00-04:00","description":"Understand scan (parallel prefix) and reduce operations - fundamental parallel compute primitives for high-performance applications.","headline":"Gridwise Scan and Reduce","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/gridwise/docs/2025/09/16/scan-and-reduce/"},"url":"http://localhost:4000/gridwise/docs/2025/09/16/scan-and-reduce/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/gridwise/docs/assets/css/style.css">
    <script src="/gridwise/docs/assets/js/main.js" defer></script></head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
    <div class="header-left">
      <a class="site-title" rel="author" href="/gridwise/">
        <span class="gradient-text">Gridwise Docs</span>
      </a>
    </div>

    <div class="header-right"><a class="header-link" href="/gridwise/examples-guide/">Examples</a>
      <a class="header-link" href="javascript:void(0)" onclick="launchExample()">Try Demo</a>
      <a class="github-button" href="https://github.com/gridwise-webgpu/gridwise" target="_blank" aria-label="GitHub">
        <svg viewBox="0 0 16 16" fill="currentColor">
          <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" />
        </svg>
      </a>
    </div>
  </div>
</header>

<script>
  function launchExample() {
    window.open('https://gridwise-webgpu.github.io/gridwise/examples/scan_pane_example.html', '_blank');
  }
</script><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Gridwise Scan and Reduce</h1>
    <div class="post-meta">
      <time class="dt-published" datetime="2025-09-16T00:00:00-04:00" itemprop="datePublished">
        Sep 16, 2025
      </time>
    </div>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><a href="https://en.wikipedia.org/wiki/Prefix_sum">Scan</a> (parallel prefix) is a fundamental parallel compute primitive useful in both other primitives as well as a wide range of application domains. (The <a href="https://en.wikipedia.org/wiki/Prefix_sum#Applications">Wikipedia page</a> describes many possible uses of scan.) Here we describe how our implementation works and how it is used in Gridwise. We published a <a href="https://dl.acm.org/doi/10.1145/3694906.3743326">paper on our scan implementation</a> at SPAA 2025. Here we instead aim for a higher-level, more informal description of our implementation.</p>

<h2 id="terminology">Terminology</h2>

<p>Scan inputs an array of <em>n</em> data elements and outputs an array of the same size. Output element <em>i</em> is the “sum” of the input elements up to element <em>i</em>. More generally, that “sum” operator can be any <a href="https://en.wikipedia.org/wiki/Monoid">monoid</a> (a binary operation with an identity element). If the operator is addition, scan is often called prefix-sum, but we can also compute a prefix-multiplication, prefix-max or -min, or many other operators. For simplicity, we will use “sum” and addition in this article. (Gridwise supports any user-specified monoid.)</p>

<p>We also use the term “reduce”, where a reduction of a set of inputs is the “sum” of all of those elements.</p>

<p>Finally, scans have two variants, exclusive and inclusive. Each output element of an <em>exclusive</em> scan is the sum of all previous items in the input, not including the current item. (<code class="language-plaintext highlighter-rouge">exclusive_out[i] = sum(in[0:i-1]).</code>) Each output element of an <em>inclusive</em> scan is the sum of all previous items in the input, up to and including the current item. (<code class="language-plaintext highlighter-rouge">inclusive_out[i] = sum(in[0:i]).</code>)</p>

<h2 id="gpu-scan-background">GPU Scan Background</h2>

<p>On GPUs, scan performance is bound by memory bandwidth. The best GPU scan implementations fully saturate the GPU’s memory system. Thus the best GPU scan implementations are those that use algorithms that require the fewest accesses to memory. The “classic” GPU way to compute scan is to divide the input into tiles, compute the reduction of all elements in each tile, compute the prefix sum of those per-tile reductions, then use the values of that per-tile prefix sum as inputs into a blockwise scan of each individual tile. This strategy is called <em>reduce-then-scan</em>. The details aren’t important; what is important is that for an <em>n</em>-element scan, we incur 3<em>n</em> memory accesses (<em>n</em> for the per-block reduction and 2<em>n</em> to read the input/write the output in the blockwise scan).</p>

<p>In 2015, Yan et al. introduced an alternate GPU-scan implementation, <a href="https://dl.acm.org/doi/10.1145/2442516.2442539">StreamScan</a>, which required only 2<em>n</em> memory accesses. Like reduce-then-scan, StreamScan computes a reduction for each input tile, but unlike reduce-then-scan, StreamScan then <em>serializes</em> the scan of the per-tile values across tile processors. This approach is called a <em>chained scan</em>. Each tile processor must wait for its predecessor to compute the reduction of all elements up to and including the predecessor’s tile. Then the tile adds its tile reduction to the global reduction and passes it to the next tile’s processor, then uses the partial sum to complete the scan of its tile. The key data structure here is the carry chain, which stores the inclusive scan of the tile reductions. The most important aspect of this implementation is that it only requires reading and writing each element once and thus incurs only 2<em>n</em> memory references, the theoretical minimum.</p>

<p>(All of the above is covered in great detail in our <a href="https://dl.acm.org/doi/10.1145/3694906.3743326">SPAA 2025 paper</a>.)</p>

<p>In an ideal world, all tile processors could run in lockstep and have equal access to memory bandwidth. However, tiles contend with each other for access to memory, and tile processors may be working on multiple tiles simultaneously. Tiles thus don’t run in lockstep; some later tiles may finish before earlier tiles, and thus have to wait for those tiles to finish. This waiting causes performance loss. In 2016, <a href="https://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back">Merrill and Garland</a> addressed this performance loss on NVIDIA hardware by enabling stalled tiles to “look back” into the carry chain to fetch the necessary values to compute their carry-chain element. This change ensured that a single stalled tile did not halt the entire scan computation, allowing <a href="https://docs.nvidia.com/cuda/cub/index.html">their implementation</a> to run at maximum throughput. CUB scan is as fast as a memory copy.</p>

<h2 id="decoupled-lookback-and-forward-progress-guarantees">Decoupled Lookback and Forward Progress Guarantees</h2>

<p>NVIDIA GPUs make a <em>forward progress guarantee</em>: once a processor begins to process a tile, it is guaranteed to make progress on that tile; the GPU scheduler ensures the processor will be allocated compute time to move forward on the processing of its tile. This guarantee is necessary for the correctness of Merrill and Garland’s implementation of decoupled lookback.</p>

<p>Unfortunately, not all GPUs provide this forward progress guarantee. <a href="https://dl.acm.org/doi/10.1145/3485508">Apple and ARM GPUs do not.</a> At any point in the scan computation, some tiles are computing a result and other tiles are waiting for a previous tile to finish its computation and write it into the carry chain. Without the forward-progress guarantee, the computing tiles may be fully blocked by waiting tiles and never make progress, leading to a completely stalled computation. On Apple hardware, as we found during the development of our scan primitive, this locks up the entire machine.</p>

<p>Deploying a WebGPU implementation that depends on a forward-progress guarantee is thus not a viable option.</p>

<h2 id="gridwises-scan-and-reduce-implementations">Gridwise’s Scan and Reduce Implementations</h2>

<h3 id="gridwises-scan">Gridwise’s Scan</h3>

<p>Gridwise implements a chained scan that does not require forward-progress guarantees. It does so in a high-performance way that allows scan to run at full memory bandwidth, even on hardware without forward-progress guarantees. Merrill and Garland’s lookback strategy allows a stalled tile processor to look back into the carry chain; we add fallback capability to allow a stalled tile processor to redundantly compute per-tile reductions, and to do so using the full parallelism of the stalled tile processor.</p>

<p>Lookback and fallback were challenging to implement correctly.</p>

<h3 id="gridwises-reduce">Gridwise’s Reduce</h3>

<p>The carry chain in a chained scan stores the inclusive scan of the reduction of each tile. The last element in that carry chain is the sum of all input tiles and is thus the reduction of the entire input. A reduce can thus be implemented using the existing scan machinery (and run at full memory bandwidth). A traditional reduce implementation (computing tile reductions in parallel then reducing the tile reductions into a single value) would likely run just as fast, but would require a different implementation, so we have chosen to use the chained-scan implementation as Gridwise’s reduce. When configured as a reduction primitive, our scan implementation leaves out any scan-specific computation (e.g., we don’t have to compute the final per-tile scan).</p>

<h3 id="leveraging-subgroups">Leveraging Subgroups</h3>

<p>WebGPU’s optional <a href="https://www.w3.org/TR/webgpu/#subgroups">subgroups</a> feature enables WebGPU programs to use SIMD instructions within a workgroup. These can deliver significant performance gains for several reasons: they leverage custom hardware for the computation itself; they do not have to route data through workgroup memory; they require one hardware instruction to do what would take many hardware instructions in emulation; and they require fewer barriers. Gridwise has some, but incompletely deployed, <a href="subgroup-strategy.html">support for emulating SIMD instructions</a>. Our initial performance testing indicated that scan was 2.5x slower using subgroup emulation vs. using subgroup hardware.</p>

<p>It is possible that the fastest scan and reduce implementations in the absence of subgroup hardware are not chained ones. We have not investigated this at all. In general, in Gridwise, we expect that subgroup operations are available, and we use them to reduce across subgroups and workgroups, to broadcast information from one thread to others, and to compute local subgroup-sized scans as part of workgroup scans.</p>

<h2 id="configuring-and-calling-gridwise-scan-and-reduce">Configuring and Calling Gridwise Scan and Reduce</h2>

<h3 id="defining-the-primitive">Defining the primitive</h3>

<p>Declare the scan or reduce primitive as an instance of the <code class="language-plaintext highlighter-rouge">DLDFScan</code> class.  An example scan declaration:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">datatype</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">u32</span><span class="dl">"</span><span class="p">;</span> <span class="c1">// or "i32" or "f32"</span>
<span class="kd">const</span> <span class="nx">dldfscanPrimitive</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">DLDFScan</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">binop</span><span class="p">:</span> <span class="k">new</span> <span class="nx">BinOpAdd</span><span class="p">({</span> <span class="nx">datatype</span> <span class="p">}),</span>
  <span class="na">type</span><span class="p">:</span> <span class="dl">"</span><span class="s2">exclusive</span><span class="dl">"</span><span class="p">,</span>
  <span class="nx">datatype</span><span class="p">,</span> <span class="c1">// use the "datatype" string defined above</span>
  <span class="na">gputimestamps</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
<span class="p">});</span>
</code></pre></div></div>

<p>The argument is a JS object and its members may include:</p>

<ul>
  <li><strong>device</strong> (required): the GPU device on which this primitive will run.</li>
  <li><strong>datatype</strong> (required): Scans need to specify the datatype that can be scanned. Currently we support the (WGSL) types “u32”, “i32”, and “f32”, specified as strings. It is definitely possible to support more complex datatypes (e.g., structs), but this would take non-trivial engineering work.</li>
  <li><strong>binop</strong> (required): the “binary operation” aka a <a href="https://en.wikipedia.org/wiki/Monoid">monoid</a>, specified as a combination of a datatype and a binary operator that operates on that datatype. The core scan implementation is agnostic as to the binary operation; the <code class="language-plaintext highlighter-rouge">binop</code> supplies that operation. The binop class is described in more detail <a href="binop.html">here</a>.</li>
  <li><strong>type</strong>: any of <code class="language-plaintext highlighter-rouge">"exclusive"</code>, <code class="language-plaintext highlighter-rouge">"inclusive"</code>, or <code class="language-plaintext highlighter-rouge">"reduce"</code>. Default is <code class="language-plaintext highlighter-rouge">"exclusive"</code>.</li>
  <li><strong>datatype</strong> (required): currently, any WGSL scalar primitive type (<code class="language-plaintext highlighter-rouge">"u32"</code>, <code class="language-plaintext highlighter-rouge">"i32"</code>, or <code class="language-plaintext highlighter-rouge">"f32"</code>). Scan and reduce could be extended to other datatypes with some engineering effort.</li>
  <li><strong>gputimestamps</strong>: enable GPU timestamps for the primitive’s kernel calls.</li>
</ul>

<h3 id="configuring-the-primitive">Configuring the primitive</h3>

<p>Once the primitive is <em>defined</em>, it must then be <em>configured</em>. The primitive knows that it requires an input and output buffer, named <code class="language-plaintext highlighter-rouge">inputBuffer</code> and <code class="language-plaintext highlighter-rouge">outputBuffer</code>. (We use our <a href="buffer.html"><code class="language-plaintext highlighter-rouge">Buffer</code> class</a> for this.) We configure the primitive by registering data buffers with the primitive. This can be done either with a <code class="language-plaintext highlighter-rouge">primitive.registerBuffer()</code> call or as an argument to the <code class="language-plaintext highlighter-rouge">execute</code> call. (The former is preferred if we need to register the buffer(s) once and then call <code class="language-plaintext highlighter-rouge">execute</code> many times.)</p>

<p>To register a buffer, simply call <code class="language-plaintext highlighter-rouge">primitive.registerBuffer(buffer)</code>, where <code class="language-plaintext highlighter-rouge">buffer.label</code> is either <code class="language-plaintext highlighter-rouge">inputBuffer</code> or <code class="language-plaintext highlighter-rouge">outputBuffer</code>. The below code creates a <code class="language-plaintext highlighter-rouge">Buffer</code> then registers it.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">inputLength</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">20</span><span class="p">;</span>
<span class="nx">testInputBuffer</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Buffer</span><span class="p">({</span>
  <span class="nx">device</span><span class="p">,</span>
  <span class="na">datatype</span><span class="p">:</span> <span class="dl">"</span><span class="s2">f32</span><span class="dl">"</span><span class="p">,</span>
  <span class="na">length</span><span class="p">:</span> <span class="nx">inputLength</span><span class="p">,</span>
  <span class="na">label</span><span class="p">:</span> <span class="dl">"</span><span class="s2">inputBuffer</span><span class="dl">"</span><span class="p">,</span>
  <span class="na">createCPUBuffer</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="na">initializeCPUBuffer</span><span class="p">:</span> <span class="kc">true</span> <span class="cm">/* fill with default data */</span><span class="p">,</span>
  <span class="na">createGPUBuffer</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
  <span class="na">initializeGPUBuffer</span><span class="p">:</span> <span class="kc">true</span> <span class="cm">/* with CPU data */</span><span class="p">,</span>
  <span class="na">createMappableGPUBuffer</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span> <span class="cm">/* never reading this back */</span>
<span class="p">});</span>
<span class="nx">primitdldfscanPrimitiveive</span><span class="p">.</span><span class="nx">registerBuffer</span><span class="p">(</span><span class="nx">testInputBuffer</span><span class="p">);</span>
</code></pre></div></div>

<h3 id="calling-scan-or-reduce">Calling scan or reduce</h3>

<p>Once the primitive is defined and configured, simply call its <code class="language-plaintext highlighter-rouge">execute()</code> method.</p>

<p>If you have not yet registered buffers, you can specify them in the argument object as <code class="language-plaintext highlighter-rouge">inputBuffer</code> and <code class="language-plaintext highlighter-rouge">outputBuffer</code>.</p>

<p>Other possible arguments (which are timing-specific and thus which you are unlikely to use unless you are benchmarking) are:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">trials</code> with an integer argument. This will run the kernel(s) that number of times. Default: 1.</li>
  <li><code class="language-plaintext highlighter-rouge">enableGPUTiming</code> with either true or false. If true, please ensure that the device has a set of required features that include <code class="language-plaintext highlighter-rouge">timestamp-query</code>. Default: false.</li>
  <li><code class="language-plaintext highlighter-rouge">enableCPUTiming</code> with either true or false. Default: false.</li>
</ul>

<p>Note that <code class="language-plaintext highlighter-rouge">execute()</code> is declared <code class="language-plaintext highlighter-rouge">async</code>.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">await</span> <span class="nx">dldfscanPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">();</span>
<span class="c1">// or, if we want to specify buffers only when execute is called</span>
<span class="k">await</span> <span class="nx">dldfscanPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">({</span>
  <span class="na">inputBuffer</span><span class="p">:</span> <span class="nx">mySrcBuffer</span><span class="p">,</span>
  <span class="na">outputBuffer</span><span class="p">:</span> <span class="nx">myDestBuffer</span><span class="p">,</span>
<span class="p">});</span>
<span class="c1">// or (maybe if you're benchmarking)</span>
<span class="k">await</span> <span class="nx">dldfscanPrimitive</span><span class="p">.</span><span class="nx">execute</span><span class="p">({</span>
  <span class="na">trials</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="na">enableGPUTiming</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="na">enableCPUTiming</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
<span class="p">});</span>
</code></pre></div></div>

<h2 id="usage-and-performance-notes">Usage and performance notes</h2>

<p>Input lengths <em>must be</em> a multiple of 4. Pad the end of your input array with enough identity elements to make this work. (This is because internally, we use <code class="language-plaintext highlighter-rouge">vec4</code>s for computation.)</p>

<p>Scan has had extensive performance testing and the defaults are fairly stable across different GPUs. The workgroup size, for instance, is set to 256. This particular iteration of the scan kernel has barely been tested with other workgroup sizes and they are unlikely to work out of the box.</p>

<p>If we extended scan to larger datatypes (beyond 32 bits), we expect that workgroup memory consumption would become an issue. We expect we would have to reduce workgroup size accordingly.</p>

  </div>

  <a class="u-url" href="/gridwise/docs/2025/09/16/scan-and-reduce/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer">
    <div class="wrapper">
        <p>&copy; 2026 Gridwise. WebGPU compute primitives in JavaScript</p><p><a href="mailto:jowens@ece.ucdavis.edu">jowens@ece.ucdavis.edu</a></p></div>
</footer>
</body>

</html>
