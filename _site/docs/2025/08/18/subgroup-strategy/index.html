<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Gridwise WebGPU Subgroup Emulation Strategy | Gridwise</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Gridwise WebGPU Subgroup Emulation Strategy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Discover Gridwise’s approach to supporting WGSL subgroup functions while maintaining fallback compatibility for all devices." />
<meta property="og:description" content="Discover Gridwise’s approach to supporting WGSL subgroup functions while maintaining fallback compatibility for all devices." />
<link rel="canonical" href="http://localhost:4000/gridwise/docs/2025/08/18/subgroup-strategy/" />
<meta property="og:url" content="http://localhost:4000/gridwise/docs/2025/08/18/subgroup-strategy/" />
<meta property="og:site_name" content="Gridwise" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-18T00:00:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Gridwise WebGPU Subgroup Emulation Strategy" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-18T00:00:00-04:00","datePublished":"2025-08-18T00:00:00-04:00","description":"Discover Gridwise’s approach to supporting WGSL subgroup functions while maintaining fallback compatibility for all devices.","headline":"Gridwise WebGPU Subgroup Emulation Strategy","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/gridwise/docs/2025/08/18/subgroup-strategy/"},"url":"http://localhost:4000/gridwise/docs/2025/08/18/subgroup-strategy/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/gridwise/docs/assets/css/style.css">
    <script src="/gridwise/docs/assets/js/main.js" defer></script></head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
    <div class="header-left">
      <a class="site-title" rel="author" href="/gridwise/">
        <span class="gradient-text">Gridwise Docs</span>
      </a>
    </div>

    <div class="header-right"><a class="header-link" href="/gridwise/examples-guide/">Examples</a>
      <a class="header-link" href="javascript:void(0)" onclick="launchExample()">Try Demo</a>
      <a class="github-button" href="https://github.com/gridwise-webgpu/gridwise" target="_blank" aria-label="GitHub">
        <svg viewBox="0 0 16 16" fill="currentColor">
          <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" />
        </svg>
      </a>
    </div>
  </div>
</header>

<script>
  function launchExample() {
    window.open('https://gridwise-webgpu.github.io/gridwise/examples/scan_pane_example.html', '_blank');
  }
</script><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Gridwise WebGPU Subgroup Emulation Strategy</h1>
    <div class="post-meta">
      <time class="dt-published" datetime="2025-08-18T00:00:00-04:00" itemprop="datePublished">
        Aug 18, 2025
      </time>
    </div>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>WGSL’s <a href="https://gpuweb.github.io/gpuweb/wgsl/#subgroup-builtin-functions">subgroup built-in functions</a> have the potential to significantly improve performance on subgroup-capable hardware. A <a href="https://web3dsurvey.com/webgpu">large (and growing) fraction of WebGPU devices</a> support subgroups. However, writing high-performance code that supports both using subgroups when available <em>and</em> falls back to code with no subgroups is a challenge. This document describes my experience attempting to do exactly that.</p>

<p>In the below discussion, we use the term “hw” to indicate “the development experience that targets hardware-supported subgroups” and “emu” for the development experience that targets non-hardware-supported subgroups, which are not supported by WGSL and thus must be emulated”.</p>

<h2 id="goals-of-this-effort">Goals of this effort</h2>

<p>In an ideal world, this effort would have resulted in the following outcomes:</p>

<ul>
  <li>For users of primitives:
    <ul>
      <li>No code changes. The same code runs on both subgroup-capable (hw) and non-subgroup-capable (emu) hardware</li>
      <li>However, my effort did not prioritize performance for emu hardware</li>
      <li>To prioritize performance here, it is likely that we’d need separate primitive formulations for hw/emu scenarios</li>
    </ul>
  </li>
  <li>For developers of primitives:
    <ul>
      <li>Minimal additional complexity. This was not entirely achieved.</li>
    </ul>
  </li>
</ul>

<p>The checked-in code does not work out of the box for emu. It would not be excessively difficult to make it work, but it would take several hours of grungy effort. I priorized hw development, not emu development, during our scan implementation; scan is already quite complicated and keeping it working for both during active development was just not a priority.</p>

<h2 id="initial-goal-subgroupshuffle">Initial goal: subgroupShuffle</h2>

<p>Let’s begin by making one call, <a href="https://www.w3.org/TR/WGSL/#subgroupshuffle-builtin"><code class="language-plaintext highlighter-rouge">subgroupShuffle</code></a>, work in both hw and emu contexts. This call looks like:</p>

<pre><code class="language-wgsl">y = subgroupShuffle(x, id);
</code></pre>

<p>The first roadblock is that <code class="language-plaintext highlighter-rouge">subgroupShuffle</code> is not defined as an emu function. Fortunately (and intelligently), WGSL allows the programmer to directly override it (“shadow”) with a user-specified function. So let’s do that (for the emu context only). If we lack subgroup hardware, we have to communicate shuffled values through workgroup memory, so we have to declare a region of workgroup memory with one element per thread. Here, <code class="language-plaintext highlighter-rouge">source</code> is a thread index within the subgroup, and <code class="language-plaintext highlighter-rouge">sgid</code> is the <code class="language-plaintext highlighter-rouge">@builtin(subgroup_invocation_id)</code>. The code is straightforward:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_sw_subgroups: array&lt;u32, 256&gt;;
fn subgroupShuffle(x: u32, source: u32) -&gt; u32 {
  wg_sw_subgroups[sgid] = x;
  workgroupBarrier();
  return wg_sw_subgroups[source];
}
</code></pre>

<p>Great! We’re done!</p>

<p>Well, not so much. There are many challenges ahead of us.</p>

<h3 id="challenge-the-builtin-sgid">Challenge: the @builtin sgid</h3>

<p>Our first challenge is using <code class="language-plaintext highlighter-rouge">@builtin(subgroup_invocation_id) sgid</code>. In emu, this <code class="language-plaintext highlighter-rouge">@builtin</code> is not defined. We can pass it in as an argument, however.</p>

<p>Thus one possible solution is to define <code class="language-plaintext highlighter-rouge">fn subgroupShuffleWrapper(x, source, sgid)</code> and then use <code class="language-plaintext highlighter-rouge">subgroupShuffleWrapper</code> everywhere. We began our development using this strategy, but it is undesirable; it’s not reasonable to ask every possible developer within this library to use a set of different functions with different APIs than those in the spec, and it significantly complicated development. We needed a better way, which we address as part of the next challenge.</p>

<h3 id="challenge-supporting-both-hw-and-emu-with-minimal-impact-on-the-programmer">Challenge: supporting both hw and emu with minimal impact on the programmer</h3>

<p>Our second challenge is ensuring that our <code class="language-plaintext highlighter-rouge">fn subgroupShuffle</code> definition is only visible when the kernel is compiled in emu, but not in hw. How can we do this?</p>

<p>First, the WebGPU call <code class="language-plaintext highlighter-rouge">device.features.has("subgroups")</code> tells us if subgroups are supported. We can use the result of this call to declare one of two sets of functions: one that assumes subgroups are available (hw) and one that does not (emu). In our implementation, this set of functions is called <code class="language-plaintext highlighter-rouge">fnDeclarations</code>. Our syntax is not important here; what is important is what happens in hw and what happens in emu.</p>

<p>At the top of the kernel, we require <code class="language-plaintext highlighter-rouge">${this.fnDeclarations.enableSubgroupsIfAppropriate}</code>. If we are hw, this emits <code class="language-plaintext highlighter-rouge">enable subgroups;</code>; if we are emu, this emits nothing.</p>

<p>With our next declaration, we partially solve the problem we identified above, where the subgroup size and subgroup id builtins are available in hw but not in emu. If the kernel is using any subgroup calls, we require <code class="language-plaintext highlighter-rouge">${this.fnDeclarations.subgroupEmulation}</code>. In hw, this emits nothing. In emu, this declares workgroup memory (for performing the subgroup operations) and subgroup variables (subgroup size and subgroup id), all at module scope:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_sw_subgroups: array&lt;${env.datatype}, ${env.workgroupSize}&gt;;
const sgsz: u32 = ${env.workgroupSize};
var&lt;private&gt; sgid: u32;
</code></pre>

<p>However, it does not actually assign values to <code class="language-plaintext highlighter-rouge">sgsz</code> and <code class="language-plaintext highlighter-rouge">sgid</code>.</p>

<p>Next, for each subgroup call we want to make, we “declare” the call. For subgroup shuffle, in hw, we emit nothing, because <code class="language-plaintext highlighter-rouge">subgroupShuffle</code> is builtin. In emu (note we use the <code class="language-plaintext highlighter-rouge">sgid</code> variable we declared at module scope above):</p>

<pre><code class="language-wgsl">fn subgroupShuffle(x: u32, source: u32) -&gt; u32 {
  /* subgroup emulation must pass through wg_sw_subgroups */
  /* write my value to workgroup memory */
  wg_sw_subgroups[sgid] = bitcast&lt;${env.datatype}&gt;(x);
  workgroupBarrier();
  var shuffled: u32 = bitcast&lt;u32&gt;(wg_sw_subgroups[source]);
  workgroupBarrier();
  return shuffled;
}
</code></pre>

<p>In hw, each supported subgroup call emits nothing, but we also define other useful functions that are not already defined and emit different implementations for hw and emu. (Example: WGSL supports both inclusive (<code class="language-plaintext highlighter-rouge">subgroupInclusiveAdd</code>) and exclusive subgroup (<code class="language-plaintext highlighter-rouge">subgroupExclusiveAdd</code>) scans, but only if the scan operator is addition. Our function library has support for non-addition inclusive and exclusive subgroup scans for both hw and emu.)</p>

<p>Finally, we need to assign values to <code class="language-plaintext highlighter-rouge">sgsz</code> and <code class="language-plaintext highlighter-rouge">sgid</code> to functions wehre they are used. Here we use a declaration within each function, `      ${this.fnDeclarations.initializeSubgroupVars()}<code class="language-plaintext highlighter-rouge">. For hw, this does nothing. For emu, this emits </code>let sgsz: u32 = builtinsUniform.sgsz;\nlet sgid: u32 = builtinsNonuniform.sgid;`.</p>

<p>The burden on the programmer is to (1) declare necessary functions at the top of the module and (2) initialize subgroup variables at the top of each function that uses subgroups, but not to change kernel code. For a hypothetical module/kernel whose only subgroup operation is <code class="language-plaintext highlighter-rouge">subgroupShuffle</code>, that code looks like:</p>

<pre><code class="language-wgsl">${this.fnDeclarations.enableSubgroupsIfAppropriate} // must be first line of kernel
${this.fnDeclarations.subgroupEmulation}
${this.fnDeclarations.subgroupShuffle}

fn kernel() {
  ${this.fnDeclarations.initializeSubgroupVars()}
  // ...
}
</code></pre>

<h3 id="challenge-choosing-an-emulated-subgroup-size">Challenge: choosing an emulated subgroup size</h3>

<p>Finally, we will have to write each emu subgroup operation. Our third challenge is to choose a subgroup size to emulate.</p>

<p>First, we know that using hw subgroup operations will deliver better performance than emu, for several reasons.</p>

<ol>
  <li>Hardware-supported subgroup instructions will run faster than the sequences of instructions we need to emulate them</li>
  <li>Because emulated subgroups don’t run in lockstep, we will require more workgroup barriers to emulate subgroups
    <ul>
      <li>Workgroup barriers will have the largest impact in latency-sensitive and/or large-workgroup kernels</li>
    </ul>
  </li>
  <li>Emulated subgroup instructions need to run through workgroup memory, which is slower than registers</li>
  <li>Allocating additional workgroup memory (at least one word per thread of the workgroup) might decrease the number of subgroups that can fit on a processor, hurting occupancy</li>
</ol>

<p>Recall that WebGPU does not specify a subgroup size (in hw), although it does specify a minimum and maximum subgroup size. (In fact, some WebGPU-capable hardware may use different subgroup sizes across different kernels in the same application.) WebGPU developers must thus write their code assuming any subgroup size between the minimum and the maximum. Since our kernels already have to handle a range of subgroup sizes, we have some flexibility to choose a subgroup size in emu. We have 3 main choices:</p>

<ol>
  <li>Assume that very small subgroup sizes run in lockstep, and use those subgroup sizes. Then we can potentially avoid some barriers and gain some efficiency.
    <ul>
      <li>But: We can’t assume that. WebGPU does not report that information. (If it did, we could take advantage of it.)</li>
    </ul>
  </li>
  <li>Assume a comfortable subgroup size (e.g., 32), and add appropriate barriers.</li>
  <li>Since we’re going to have to put barriers everywhere anyway, assume subgroup size == workgroup size.</li>
</ol>

<p>Let’s take a step back and think about how subgroups are used. Consider a reduction across a workgroup (each thread has one item and the workgroup adds up all items). The typical pattern for a workgroup reduction leveraging subgroup support is to (a) use a subgroup reduction on each subgroup then (b) reduce across the results from each subgroup. This pattern is typical: parallelize across subgroups, then combine the results.</p>

<p>Now, if we choose alternatives 1 or 2, then it is highly likely that each workgroup will contain several subgroups. Many primitives will thus have two stages: per-subgroup, then per-workgroup. If we choose alternative 3 (subgroup size == workgroup size), then our algorithms may be simpler, because we don’t have to combine results from multiple subgroups within a workgroup. This also simplifies the code that emulates subgroups.</p>

<p>We do see one clear structural issue, though: some subgroup operations have a maximum size (e.g., <code class="language-plaintext highlighter-rouge">subgroupBallot</code> has a maximum subgroup size of 128, because it returns exactly 128 bits).</p>

<p>Nonetheless for simplicity, we currently choose to always emulate subgroups that are the size of the workgroup, recognizing that this is not a fully generalizable solution.</p>

<h2 id="summary">Summary</h2>

<p>On an Apple M3 with a high-performance scan kernel, the performance difference between hw and emu with the same kernel is ~2.5x.</p>

<p>An open question is whether it is better to write different <em>kernels</em> for hw and emu as opposed to what we did: writing different versions of subgroup functions and keeping the same kernel. The answer probably depends on the nature of the kernels. We did not explore the latter alternative at all.</p>

  </div>

  <a class="u-url" href="/gridwise/docs/2025/08/18/subgroup-strategy/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer">
    <div class="wrapper">
        <p>&copy; 2026 Gridwise. WebGPU compute primitives in JavaScript</p><p><a href="mailto:jowens@ece.ucdavis.edu">jowens@ece.ucdavis.edu</a></p></div>
</footer>
</body>

</html>
