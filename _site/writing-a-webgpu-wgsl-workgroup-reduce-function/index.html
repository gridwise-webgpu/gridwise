<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Abstraction Challenges in Writing a WebGPU/WGSL Workgroup Reduce Function | Gridwise</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Abstraction Challenges in Writing a WebGPU/WGSL Workgroup Reduce Function" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A practical walkthrough of implementing a workgroupReduce function in WGSL, exploring language challenges and abstraction pain points." />
<meta property="og:description" content="A practical walkthrough of implementing a workgroupReduce function in WGSL, exploring language challenges and abstraction pain points." />
<link rel="canonical" href="http://localhost:4000/gridwise/writing-a-webgpu-wgsl-workgroup-reduce-function/" />
<meta property="og:url" content="http://localhost:4000/gridwise/writing-a-webgpu-wgsl-workgroup-reduce-function/" />
<meta property="og:site_name" content="Gridwise" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Abstraction Challenges in Writing a WebGPU/WGSL Workgroup Reduce Function" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"A practical walkthrough of implementing a workgroupReduce function in WGSL, exploring language challenges and abstraction pain points.","headline":"Abstraction Challenges in Writing a WebGPU/WGSL Workgroup Reduce Function","url":"http://localhost:4000/gridwise/writing-a-webgpu-wgsl-workgroup-reduce-function/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/gridwise/docs/assets/css/style.css">
    <script src="/gridwise/docs/assets/js/main.js" defer></script></head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
    <div class="header-left">
      <a class="site-title" rel="author" href="/gridwise/">
        <span class="gradient-text">Gridwise Docs</span>
      </a>
    </div>

    <div class="header-right"><a class="header-link" href="/gridwise/examples-guide/">Examples</a>
      <a class="header-link" href="javascript:void(0)" onclick="launchExample()">Try Demo</a>
      <a class="github-button" href="https://github.com/gridwise-webgpu/gridwise" target="_blank" aria-label="GitHub">
        <svg viewBox="0 0 16 16" fill="currentColor">
          <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" />
        </svg>
      </a>
    </div>
  </div>
</header>

<script>
  function launchExample() {
    window.open('https://gridwise-webgpu.github.io/gridwise/examples/scan_pane_example.html', '_blank');
  }
</script><div class="main-container">
  <!-- Modern Sidebar Navigation -->
  <aside class="docs-sidebar" id="docsSidebar">
    <div class="sidebar-content">
      <div class="sidebar-header">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"/>
          <path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"/>
        </svg>
        <h1>Documentation</h1>
      </div>

      <div class="search-box">
        <svg class="search-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <circle cx="11" cy="11" r="8"/>
          <path d="m21 21-4.35-4.35"/>
        </svg>
        <input type="text" id="docsSearch" placeholder="Search docs..." />
      </div>

      <nav class="docs-nav"><div class="nav-section">
          <h3 class="nav-section-title">Getting Started</h3>
          <ul>
            <li>
              <a href="/gridwise/getting-started/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253" />
                </svg>
                <span>Introduction</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/installation/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z" />
                </svg>
                <span>Quick Start</span>
              </a>
            </li>
          </ul>
        </div><div class="nav-section">
          <h3 class="nav-section-title">Core Concepts</h3>
          <ul>
            <li>
              <a href="/gridwise/architecture/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 5a1 1 0 011-1h4a1 1 0 011 1v7a1 1 0 01-1 1H5a1 1 0 01-1-1V5zM14 5a1 1 0 011-1h4a1 1 0 011 1v7a1 1 0 01-1 1h-4a1 1 0 01-1-1V5zM4 16a1 1 0 011-1h4a1 1 0 011 1v3a1 1 0 01-1 1H5a1 1 0 01-1-1v-3zM14 16a1 1 0 011-1h4a1 1 0 011 1v3a1 1 0 01-1 1h-4a1 1 0 01-1-1v-3z" />
                </svg>
                <span>Architecture</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/primitive-design/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 9l3 3-3 3m5 0h3M5 20h14a2 2 0 002-2V6a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z" />
                </svg>
                <span>Primitive Design</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/subgroup-strategy/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 3v2m6-2v2M9 19v2m6-2v2M5 9H3m2 6H3m18-6h-2m2 6h-2M7 19h10a2 2 0 002-2V7a2 2 0 00-2-2H7a2 2 0 00-2 2v10a2 2 0 002 2zM9 9h6v6H9V9z" />
                </svg>
                <span>Subgroup Strategy</span>
              </a>
            </li>
          </ul>
        </div><div class="nav-section">
          <h3 class="nav-section-title">Primitives</h3>
          <ul>
            <li>
              <a href="/gridwise/scan-and-reduce/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z" />
                </svg>
                <span>Scan and Reduce</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/sort/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16V4m0 0L3 8m4-4l4 4m6 0v12m0 0l4-4m-4 4l-4-4" />
                </svg>
                <span>Sort</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/binop/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z" />
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                </svg>
                <span>Binary Operations</span>
              </a>
            </li>
          </ul>
        </div><div class="nav-section">
          <h3 class="nav-section-title">Advanced</h3>
          <ul>
            <li>
              <a href="/gridwise/buffer/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 7v10c0 2.21 3.582 4 8 4s8-1.79 8-4V7M4 7c0 2.21 3.582 4 8 4s8-1.79 8-4M4 7c0-2.21 3.582-4 8-4s8 1.79 8 4m0 5c0 2.21-3.582 4-8 4s-8-1.79-8-4" />
                </svg>
                <span>Buffer Management</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/timing-strategy/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z" />
                </svg>
                <span>Timing Strategy</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/webgpu-object-caching-strategy/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 5a1 1 0 011-1h4a1 1 0 011 1v7a1 1 0 01-1 1H5a1 1 0 01-1-1V5zM14 5a1 1 0 011-1h4a1 1 0 011 1v7a1 1 0 01-1 1h-4a1 1 0 01-1-1V5zM4 16a1 1 0 011-1h4a1 1 0 011 1v3a1 1 0 01-1 1H5a1 1 0 01-1-1v-3zM14 16a1 1 0 011-1h4a1 1 0 011 1v3a1 1 0 01-1 1h-4a1 1 0 01-1-1v-3z" />
                </svg>
                <span>Object Caching</span>
              </a>
            </li>
            <li>
              <a href="/gridwise/builtins-strategy/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z" />
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                </svg>
                <span>Builtins Strategy</span>
              </a>
            </li>
          </ul>
        </div><div class="nav-section">
          <h3 class="nav-section-title">Examples</h3>
          <ul><li>
              <a href="/gridwise/examples/reduce/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" />
                </svg>
                <span>Reduce Example</span>
              </a>
            </li><li>
              <a href="/gridwise/examples/scan/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" />
                </svg>
                <span>Scan Example</span>
              </a>
            </li><li>
              <a href="/gridwise/examples/sort/" >
                <svg class="nav-icon" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" />
                </svg>
                <span>Sort Example</span>
              </a>
            </li></ul>
        </div></nav>
    </div>

    <!-- Sidebar Footer -->
    <div class="sidebar-footer">
      <a href="https://github.com/gridwise-webgpu/gridwise" target="_blank" class="github-link">
        <svg class="github-icon" viewBox="0 0 16 16" fill="currentColor">
          <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" />
        </svg>
        <span>GitHub</span>
      </a>
    </div>
  </aside>

  <!-- Main Content Area -->
  <main class="docs-content">
    <div class="content-inner"><div class="docs-hero">
        <div class="badge">
          <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <polygon points="13 2 3 14 12 14 11 22 21 10 12 10 13 2"/>
          </svg>
          <span>Documentation</span>
        </div>
        <h1>Abstraction Challenges in Writing a WebGPU/WGSL Workgroup Reduce Function</h1><p class="lead">A practical walkthrough of implementing a workgroupReduce function in WGSL, exploring language challenges and abstraction pain points.</p></div><article class="post">
        <div class="post-content">
          <p>In this post, we’ll walk through the process of writing a <code class="language-plaintext highlighter-rouge">workgroupReduce</code> function in WGSL. We write this function as if we were a library writer who would implement <code class="language-plaintext highlighter-rouge">workgroupReduce</code> with the intent that other unknown developers will call our function. Our goal is to explore the WGSL issues facing the library writer. Through this practical example of creating a <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function, we will identify and discuss several pain points in the language.</p>

<hr />

<h2 id="summary-of-pain-points">Summary of Pain Points</h2>

<p>When writing a generic library function in WGSL, we identified several key difficulties:</p>

<ul>
  <li><strong>Explicit Built-in Declarations:</strong> WGSL’s requirement to explicitly declare <code class="language-plaintext highlighter-rouge">@builtins</code> complicates APIs.</li>
  <li><strong>Inconsistent Built-in Variants:</strong> Not all built-ins have both 3D and 1D variants.</li>
  <li><strong>Module-Scoped Workgroup Memory:</strong> Declaring workgroup memory only at the module scope harms modularity.</li>
  <li><strong>Lack of Generics:</strong> The absence of function overloading or templating makes it difficult to write generic APIs.</li>
</ul>

<p>These limitations lead to a choice between two library design patterns: a few complex kernels using template-literal string pasting, or many simple kernels using metaprogramming.</p>

<hr />

<h2 id="scenario-a-reduceworkgroup-function">Scenario: A reduceWorkgroup Function</h2>

<p>We will focus on creating a <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function that will be incorporated into a primitive library. We expect external users will face a need to input a linear array of data and have each workgroup compute the sum of a sub-section of that data. Our implementation, as part of a library, will allow them to do so without concern for how the reduction is implemented.</p>

<p>The semantics of the function are as follows: consider a workgroup of N invocations (e.g., N = 128); workgroup W will compute the sum of <code class="language-plaintext highlighter-rouge">input[W*N:W*(N+1))</code>, and each invocation in the workgroup will receive this sum as the return value of a function call.</p>

<h3 id="desired-function-call-caller-wgsl-definition">Desired Function Call: Caller (WGSL Definition)</h3>

<p>Ideally, making the function call from within a WGSL kernel would be simple, with the minimal call looking something like</p>

<pre><code class="language-wgsl">...
val = reduceWorkgroup(ptr);
...
</code></pre>

<p>Here we assume that <code class="language-plaintext highlighter-rouge">ptr</code> is an address pointing to an item within a linear input array, and that the private variable <code class="language-plaintext highlighter-rouge">val</code> and the deferenced value at <code class="language-plaintext highlighter-rouge">ptr</code> have the same datatype. If the workgroup has <code class="language-plaintext highlighter-rouge">W</code> invocations, then <code class="language-plaintext highlighter-rouge">val</code>, for every invocation in workgroup <code class="language-plaintext highlighter-rouge">W</code>, will assume the value <code class="language-plaintext highlighter-rouge">reduce(ptr[W*N:W*(N+1)))</code>.</p>

<p>This interface does not specify the reduction operation (for instance, addition, max, or min), nor the datatype. Possible options to address the former include:</p>

<ul>
  <li>A separate reduction function for each operation (<code class="language-plaintext highlighter-rouge">reduceAddWorkgroup</code>, <code class="language-plaintext highlighter-rouge">reduceMinWorkgroup</code>, etc.)</li>
  <li>A default operation (e.g., <code class="language-plaintext highlighter-rouge">add</code>)</li>
  <li>Separately defining an operation (a “binop” == a monoid) that must be explicitly set by the caller and implicitly used by the function</li>
</ul>

<p>However, we do not further discuss this issue in this document.</p>

<h3 id="desired-function-call-callee">Desired Function Call: Callee</h3>

<p>We would also like the callee function/kernel to be as simple as possible. The minimum kernel that calls our function, and places the output into an output array, would look something like this:</p>

<pre><code class="language-wgsl">@compute @workgroup_size(128) fn reduceKernel(
  @builtin(local_invocation_index) lidx: u32,
  @builtin(workgroup_id) wgid: vec3u
) {
  let r = reduceWorkgroup(&amp;in);
  if (lidx == 0) {
    out[wgid.x] = r;
  }
}
</code></pre>

<h3 id="issues-with-the-above-kernel">Issues with the above kernel</h3>

<h4 id="builtins-must-be-explicitly-declared">Builtins must be explicitly declared</h4>

<p>The above kernel has 5 lines of code. 2 of them are declaring built-ins. WGSL requires these declarations, but other languages have made different choices. Why are variables like <code class="language-plaintext highlighter-rouge">local_invocation_index</code> and <code class="language-plaintext highlighter-rouge">workgroup_id</code> not available within a kernel without the need for these declarations?</p>

<p>Possible ways to remove the need for these declarations include</p>

<ul>
  <li>Making a builtin variable available within kernels (e.g., CUDA’s <code class="language-plaintext highlighter-rouge">threadIdx</code>)</li>
  <li>Making a function call that retrieves a builtin variable available within kernels (e.g., SYCL’s <code class="language-plaintext highlighter-rouge">get_id()</code>)</li>
</ul>

<h4 id="some-3d-builtins-lack-a-1d-variant">Some 3D builtins lack a 1D variant</h4>

<p>The use of <code class="language-plaintext highlighter-rouge">wgid</code> above reflects a common implementation pattern: we logically have a 1D data space (<code class="language-plaintext highlighter-rouge">in</code>, <code class="language-plaintext highlighter-rouge">out</code>) and thus want our workgroups to also be organized as a 1D data space. However, the only access we have to the workgroup id is through a 3D builtin. Above, we just assume that such a builtin only uses the <code class="language-plaintext highlighter-rouge">.x</code> part of the <code class="language-plaintext highlighter-rouge">workgroup_id</code> builtin, but this assumption is checked nowhere.</p>

<p>It would be convenient to have a 1D builtin equivalent for every 3D builtin (specifically, WGSL lacks <code class="language-plaintext highlighter-rouge">workgroup_index</code> and <code class="language-plaintext highlighter-rouge">global_invocation_index</code>).</p>

<h3 id="implementing-reduceworkgroup">Implementing reduceWorkgroup</h3>

<p>Now let’s turn to actually implementing the <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function.</p>

<p>An initial, simple implementation of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> might allocate an workgroup-memory variable and use <code class="language-plaintext highlighter-rouge">atomicAdd</code> to accumulate inputs into it. It might look like this:</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[?]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<h4 id="leaky-abstraction-wg_temp">Leaky abstraction: <code class="language-plaintext highlighter-rouge">wg_temp</code></h4>

<p>The above code uses storage <code class="language-plaintext highlighter-rouge">wg_temp</code> located in workgroup memory. WGSL requires that variables in the workgroup address space be declared at the module scope, which is a significant limitation on modularity. Who declares this storage? How big is it? Why can’t I declare it within the <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function?</p>

<p>We could declare the workgroup memory <code class="language-plaintext highlighter-rouge">wg_temp_reduceWorkgroup</code> at the module scope as follows:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_temp_reduceWorkgroup: array&lt;atomic&lt;u32&gt;, 1&gt;;
fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u,
                  ) -&gt; u32 {
  atomicAdd(&amp;wg_temp_reduceWorkgroup[0], input[?]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp_reduceWorkgroup[0]);
}
</code></pre>

<p>However, such a declaration by the writer of a library might have a name conflict for the workgroup memory <code class="language-plaintext highlighter-rouge">wg_temp_reduceWorkgroup</code>, either within the library or with a different allocation defined by the user of the library. Note that if we define many different <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> functions, for instance ones that are specialized to datatype and reduction operation, we also must declare a different workgroup memory variable for each of them. Then a compiler would have to identify which specialized functions are actually used and only instantiate their workgroup memory regions. Finally, while it is likely that a complex workload that used many different reduce functions from this library could potentially share the same workgroup memory region used for the accumulation, the above code would not allow this sharing.</p>

<p>We might consider a language change that allows workgroup memory to be declared within a function instead of at module scope. This potentially eliminates name conflicts. But the programmer still must account for the use of workgroup memory.</p>

<h4 id="specifying-the-input-region">Specifying the input region</h4>

<p>The above code has the line <code class="language-plaintext highlighter-rouge">atomicAdd(&amp;wg_temp[0], input[?])</code>. How do we fill in the <code class="language-plaintext highlighter-rouge">[?]</code>?</p>

<p>What we want is for each individual instance (thread) to fetch the input value that corresponds to its global instance id. Instance 0 fetches <code class="language-plaintext highlighter-rouge">input[0]</code>, instance 128 fetches <code class="language-plaintext highlighter-rouge">input[128]</code>, etc. This information is only available through a builtin, which requires that the enclosing kernel must input that builtin and that the function add an additional input:</p>

<pre><code class="language-wgsl">@compute @workgroup_size(128) fn reduceKernel(
  @builtin(global_invocation_id) gid: vec3u,
  @builtin(local_invocation_index) lidx: u32,
  @builtin(workgroup_id) wgid: vec3u) {
  let r = reduceWorkgroup(&amp;in, gid.x);
  if (lidx == 0) {
    out[wgid.x] = r;
  }
}
</code></pre>

<p>While this second argument to <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> adds flexibility, it would be nice to not require the kernel author to plumb a builtin through the kernel if that builtin was used in the default way.</p>

<p>(Look at the use of <code class="language-plaintext highlighter-rouge">wgid.x</code> in the above kernel and recall the comment above that “It would be useful to have a 1D builtin equivalent for every 3D builtin (specifically, <code class="language-plaintext highlighter-rouge">workgroup_index</code> and <code class="language-plaintext highlighter-rouge">global_invocation_index</code>)”—here is a use for <code class="language-plaintext highlighter-rouge">workgroup_index</code>.)</p>

<h2 id="a-working-implementation">A Working Implementation</h2>

<p>Kernel (WGSL) code:</p>

<pre><code class="language-wgsl">@compute @workgroup_size(128) fn reduceKernel(
  @builtin(global_invocation_id) gid: vec3u,
  @builtin(local_invocation_index) lidx: u32,
  @builtin(workgroup_id) wgid: vec3u) {
  let r = reduceWorkgroup(&amp;in, gid.x);
  if (lidx == 0) {
    out[wgid.x] = r;
  }
}
</code></pre>

<p>Implementation of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code>:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_temp: array&lt;atomic&lt;u32&gt;, 1&gt;;

fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>Note that nothing in the actual kernel itself is specific to datatype. (Or workgroup size, for that matter.)</p>

<h3 id="generalizing-our-implementation-">Generalizing our implementation …</h3>

<h4 id="-across-datatypes">… across datatypes</h4>

<p>So, as an experiment, let’s consider adding another <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> function that reduces <code class="language-plaintext highlighter-rouge">f32</code> values rather than the <code class="language-plaintext highlighter-rouge">u32</code> values above. The callee code does not change, but the library function implementation does:</p>

<pre><code class="language-wgsl">var&lt;workgroup&gt; wg_temp: array&lt;atomic&lt;f32&gt;, 1&gt;;

fn reduceWorkgroup(input: ptr&lt;storage, array&lt;f32&gt;, read&gt;,
                   gid: vec3u) -&gt; f32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>This addition of an <code class="language-plaintext highlighter-rouge">f32 reduceWorkgroup</code> function uncovers two new issues:</p>

<ul>
  <li>The <code class="language-plaintext highlighter-rouge">wg_temp</code> workgroup variable now has a name collision between the <code class="language-plaintext highlighter-rouge">u32</code> variant and the <code class="language-plaintext highlighter-rouge">f32</code> variant.</li>
  <li>We now have two different functions named <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code>, which is not permitted in WGSL. We can’t overload a function name. Type-specific dispatch would be useful here.</li>
</ul>

<p>The careful WGSL developer notices a third issue: there is no <code class="language-plaintext highlighter-rouge">atomicAdd</code> on <code class="language-plaintext highlighter-rouge">f32</code> variables.</p>

<p>The above issues motivate a library design that has different functions for each datatype, specifically here <code class="language-plaintext highlighter-rouge">reduceWorkgroupU32</code> and <code class="language-plaintext highlighter-rouge">reduceWorkgroupF32</code>.</p>

<h4 id="-across-storage-locations">… across storage locations</h4>

<p>Recall that our <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> signature shows that the input data is located in global (storage) memory:</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>Let’s consider a <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> that instead stored its input in workgroup memory. It would be ideal if we could support inputs in either global (storage) or workgroup memory without any changes to the code.</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;workgroup, array&lt;u32&gt;, SIZE&gt;,
                   gid: vec3u) -&gt; u32 {
  atomicAdd(&amp;wg_temp[0], input[gid.x]);
  workgroupBarrier();
  return atomicLoad(&amp;wg_temp[0]);
}
</code></pre>

<p>Note that the <em>bodies</em> of these two functions are identical; only the argument type is different. Nonetheless WGSL requires we implement both functions separately because they have different argument types. This argues for a library designer separately implementing <code class="language-plaintext highlighter-rouge">reduceWorkgroupWGU32</code> and <code class="language-plaintext highlighter-rouge">reduceWorkgroupStorageU32</code>.</p>

<h2 id="a-more-realistic-workgroup-reduce-function">A More Realistic Workgroup Reduce Function</h2>

<p>The above functions are simple but not high-performance, because all instances must serialize on the atomic reduction variable. Higher-performance reduce implementations instead exploit parallelism across instances within a workgroup. As well, the highest-performance implementations will likely make use of WebGPU subgroups.</p>

<p>One of the challenges of subgroups is that their size is not constant within WebGPU. In fact, different kernels running within the same application on some WebGPU-capable hardware may not even share the same subgroup size. If we wish to write a subgroup-size-agnostic kernel, we must support all possible subgroup sizes within that kernel. The challenge with such an implementation is that any allocation that depends on the subgroup size must perform a worst-case allocation that works with any subgroup size.</p>

<p>WebGPU provides two adapter properties—<code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE</code> and <code class="language-plaintext highlighter-rouge">MAX_SUBGROUP_SIZE</code>—that we can use to perform allocations. Below is the start of a high-performance workgroup-reduce kernel that requires a workgroup-memory allocation for partial reductions. The size of the workgroup-memory allocation is directly proportional to the workgroup size (variable: <code class="language-plaintext highlighter-rouge">{$workgroupSize}</code>) and inversely proportional to the subgroup size (variable: <code class="language-plaintext highlighter-rouge">${MIN_SUBGROUP_SIZE}</code>).</p>

<pre><code class="language-wgsl">const BLOCK_DIM: u32 = ${workgroupSize};
const TEMP_WG_MEM_SIZE = BLOCK_DIM / ${MIN_SUBGROUP_SIZE};
var&lt;workgroup&gt; wg_temp: array&lt;u32, TEMP_WG_MEM_SIZE&gt;;

fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u, lidx: u32, sgid: u32, sgsz: u32
                   ) -&gt; u32 {
  let sid = lidx / sgsz;
  let lane_log = u32(countTrailingZeros(sgsz)); /* log_2(sgsz) */
  let local_spine: u32 = BLOCK_DIM &gt;&gt; lane_log;
  /* BLOCK_DIM / subgroup size; how many partial reductions in this tile? */
  // ...
}
</code></pre>

<p>The value of <code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE</code> (and more broadly, any value that is adapter-dependent and thus not determinable until runtime) has two impacts on this code:</p>

<ul>
  <li>First, the allocation is inversely proportional to <code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE</code>. We would like to only allocate the memory we need. It is not clear in WGSL what the right way to perform this specialization might be: static (compile-time) specialization, such as what a C++ template provides, or instead runtime compilation that incorporates the adapter property.</li>
  <li>Second, the algorithm can be made simpler if the subgroup sizes are large enough (specifically, if <code class="language-plaintext highlighter-rouge">MIN_SUBGROUP_SIZE * MIN_SUBGROUP_SIZE &gt;= workgroupSize</code>). It would be desirable to have the maximum possible compile-time specialization for such a decision rather than making all aspects of the decision at runtime.</li>
</ul>

<p>In summary, the presence of an adapter-specific property, only discoverable at runtime, mandates making runtime decisions that developers would prefer to do at compile time.</p>

<h2 id="multiple-implementations-are-interesting-but-builtins-complicate-function-signatures">Multiple implementations are interesting, but builtins complicate function signatures</h2>

<p>It would be desirable for a library user to write code that could call <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> but not have to choose which implementation of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code>; instead, that choice could be made by the underlying library in some static or runtime-dependent way. This ability would also be useful for the library developer, who might want to try different <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> implementations in real workloads to determine the fastest one without having to change the function call within the workload. However, if each <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> implementation had a different function signature, this would be impossible.</p>

<p>Unfortunately, the function signatures of different implementations of <code class="language-plaintext highlighter-rouge">reduceWorkgroup</code> (above) are different.</p>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u) -&gt; u32
</code></pre>

<pre><code class="language-wgsl">fn reduceWorkgroup(input: ptr&lt;storage, array&lt;u32&gt;, read&gt;,
                   gid: vec3u, lidx: u32, sgid: u32, sgsz: u32
                   ) -&gt; u32
</code></pre>

<p>The difference is which builtins are used. Builtins must be passed in through the function signature, and if different implementations use a different set of builtins, their function signatures will differ.</p>

<p>One remedy is to pass every builtin into every function. This is verbose and quite kludgey. Instead we have addressed this problem by …</p>

<h3 id="packing-built-ins-into-structs">Packing Built-ins into Structs</h3>

<p>To simplify the function signatures, we pack built-ins into structs:</p>

<p>Code snippet</p>

<pre><code class="language-wgsl">struct Builtins {
 @builtin(global_invocation_id) gid: vec3u,
 @builtin(num_workgroups) nwg: vec3u,
 @builtin(workgroup_id) wgid: vec3u,
 @builtin(local_invocation_index) lidx: u32,
 @builtin(local_invocation_id) lid: vec3u,
 @builtin(subgroup_size) sgsz: u32,
 @builtin(subgroup_invocation_id) sgid: u32
}
</code></pre>

<p>We also divide those builtins into two different structs, differentiated by whether the member is uniform or non-uniform. The use of <code class="language-plaintext highlighter-rouge">BuiltinsUniform</code> is sometimes necessary to ensure workgroup or subgroup uniformity.</p>

<pre><code class="language-wgsl">struct BuiltinsNonuniform {
  @builtin(global_invocation_id) gid: vec3u /* 3D thread id in compute shader grid */,
  @builtin(local_invocation_index) lidx: u32 /* 1D thread index within workgroup */,
  @builtin(local_invocation_id) lid: vec3u /* 3D thread index within workgroup */,
  @builtin(subgroup_invocation_id) sgid: u32 /* 1D thread index within subgroup */
}

struct BuiltinsUniform {
  @builtin(num_workgroups) nwg: vec3u /* == dispatch */,
  @builtin(workgroup_id) wgid: vec3u /* 3D workgroup id within compute shader grid */,
  @builtin(subgroup_size) sgsz: u32 /* subgroup size */
}
</code></pre>

<p>This allows for a cleaner function signature, but mandates that the library user must use the library’s naming conventions.</p>

<h2 id="conclusion">Conclusion</h2>

<p>We conclude by reiterating the main pain points in WGSL that make writing generic compute libraries challenging:</p>

<ul>
  <li>Explicit declaration of @builtins.</li>
  <li>Lack of 1D variants for all built-ins.</li>
  <li>Module-scoped workgroup memory.</li>
  <li>Lack of function overloading and templating.</li>
</ul>

<p>These limitations force library designers to choose between metaprogramming to generate many specialized functions or using template literals to create a few complex kernels.</p>

        </div>
      </article>
    </div>
  </main>
</div>

<script>
  // Save and restore sidebar scroll position
  (function() {
    const sidebar = document.querySelector('.docs-sidebar');
    if (!sidebar) return;
    
    // Restore scroll position immediately
    const savedScrollPos = sessionStorage.getItem('sidebarScrollPos');
    if (savedScrollPos) {
      sidebar.scrollTop = parseInt(savedScrollPos);
    }
    
    // Save on scroll
    let scrollTimer;
    sidebar.addEventListener('scroll', function() {
      clearTimeout(scrollTimer);
      scrollTimer = setTimeout(function() {
        sessionStorage.setItem('sidebarScrollPos', sidebar.scrollTop);
      }, 100);
    });
    
    // Save on link click and restore after navigation
    sidebar.querySelectorAll('a').forEach(function(link) {
      link.addEventListener('click', function(e) {
        sessionStorage.setItem('sidebarScrollPos', sidebar.scrollTop);
      });
    });
    
    // Restore again after a short delay to handle any reflows
    window.addEventListener('load', function() {
      if (savedScrollPos) {
        sidebar.scrollTop = parseInt(savedScrollPos);
      }
    });
  })();
</script>
<footer class="site-footer">
    <div class="wrapper">
        <p>&copy; 2026 Gridwise. WebGPU compute primitives in JavaScript</p><p><a href="mailto:jowens@ece.ucdavis.edu">jowens@ece.ucdavis.edu</a></p></div>
</footer></body>

</html>
